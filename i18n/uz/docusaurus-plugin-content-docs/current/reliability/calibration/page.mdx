---
sidebar_position: 10
title: "ðŸ”´ LLMlarni kalibrlash"
---


# LLMlarni kalibrlash

Baâ€™zi bir tarafkashliklarni LLMlar namoyon qiladigan holatlarni **output** ni kalibrlash orqali bartaraf etish mumkin
taqsimotlar**(@zhao2021calibrate).

**Chiqarish taqsimotini kalibrlash aynan nimani anglatadi?**

Keling, tezkor misolni koâ€˜rib chiqamiz: Aytaylik, bizda ikki mumkin boâ€˜lgan yorliq, `Positive` va `Negative` boâ€˜lgan  sentiment analysis  vazifasi bor.
 LLM  ga `Input: nothing Sentiment: ` bilan prompt berilganda nima sodir boâ€˜lishini koâ€˜rib chiqing.
Bu kiritmada LLM foydalanishi mumkin boâ€˜lgan hech qanday _kontekst_ yoâ€˜q, shuning uchun u sentiment aniqlay olmaydi
bashorat, shuning uchun bu **kontekstsiz** kiritma deb ataladi.

Chunki `nothing` na ijobiy, na salbiy tushuncha hisoblanadi, biz LLM dan `Positive` va `Negative` uchun taxminan 0.5 ehtimollikni kutamiz. Biroq, koâ€˜pincha (va ushbu misolda ham) bu holat kuzatilmaydi.

```
p("Positive" | "Input: nothing Sentiment:") = 0.9

p("Negative" | "Input: nothing Sentiment:") = 0.1
```

Ushbu kontekstdan mustaqil kirish uchun ushbu yorliq ehtimollari berilgan boâ€˜lsa, biz bilamizki, LLM ning
**output distribution** ehtimol tarafkash boâ€˜ladi
`Positive` yorligâ€˜iga tomon. Bu LLMning `Positive` ni afzal koâ€˜rishiga olib kelishi mumkin
barcha kirishlar uchun, hatto kirish haqiqatan ham ijobiy bo'lmasa ham.

Agar biz qandaydir tarzda chiqish taqsimotini **kalibrlash** imkoniga ega boâ€˜lsak, shunda kontekstdan mustaqil
kiritmalar uchun ham `Positive`, ham `Negative` uchun 0.5 ehtimollik belgilanadi,
shunda biz koâ€˜pincha `Positive` ga boâ€˜lgan ogâ€˜ishlarni olib tashlashimiz mumkin va LLM yanada ishonchli boâ€˜ladi
kontekstsiz kirishlar va kontekstli kirishlarda ham.

## Texnik boâ€˜lmagan yechim

Ushbu muammoning texnik bo'lmagan yechimi shunchaki bir nechta misollarni taqdim etishdir, bu yerda
kontekstsiz namunalarga har ikkala holat uchun samarali tarzda 0.5 ehtimollik beriladi
`Ijobiy` va `Salbiy`.

Masalan, biz har bir kontekstdan mustaqil holatni koâ€˜rsatadigan quyidagi few shot misollarni taqdim etishimiz mumkin
namuna ham `Positive`, ham `Negative` sifatida tasniflanmoqda:

```
Input: I hate this movie. Sentiment: Negative
Input: I love this movie. Sentiment: Positive
Input: N/A Sentiment: Positive
Input: N/A Sentiment: Negative
Input: nothing Sentiment: Positive
Input: nothing Sentiment: Negative
Input: I like eggs. Sentiment:
```

Mening bilishimcha, bu yechim adabiyotda oâ€˜rganilmagan va men ishonchim komil emas
u amalda qanchalik yaxshi ishlashini. Biroq, bu nima ekanligini koâ€˜rsatadigan oddiy yechimdir
kalibrlash erishmoqchi boâ€˜lgan narsadir.

## Texnik yechim

Buning yana bir yechimi **contextual calibration**(@zhao2021calibrate) boâ€˜lib, bu yerda biz
maxsus kalibrlash parametrlarini sozlang, bu esa kontekstdan mustaqil kiritmalarni taâ€™minlaydi, masalan
`Input: nothing Sentiment: ` har ikkala yorliq uchun ham taxminan 0.5 ehtimollik belgilanadi.
E'tibor bering, amalda bu usul bir nechta turli kontekstdan holi kirishlar ustida kalibrlashni amalga oshiradi (masalan, `Input: N/A Sentiment: `, `Input: [MASK] Sentiment: `). U kalibrlash parametrlarini o'rtacha qiladi, bu
har bir kontekstdan mustaqil kiritma uchun eng yaxshi natija beradigan kalibrlash parametrlarini topish uchun eng yaxshi usulda ishlaydi.

### Misol

Keling, bir kontekstdan mustaqil kiritma uchun kalibrlash parametrlarini hisoblash misolini koâ€˜rib chiqamiz. E'tibor bering,
bu misol GPT-3 bilan takrorlab boâ€˜lmaydi, chunki uni faqat `Positive` va `Negative` yorliqlari bilan cheklab boâ€˜lmaydi.

Yuqoridagi misolni yana bir bor koâ€˜rib chiqing, bunda LLM yorliqlarga quyidagi ehtimolliklarni belgilaydi
kontekstsiz kiritma uchun:

```
p("Positive" | "Input: nothing Sentiment:") = 0.9

p("Negative" | "Input: nothing Sentiment:") = 0.1
```

Biz shunday ehtimollik taqsimoti q ni topmoqchimizki,

```
q("Positive" | "Input: nothing Sentiment:") = 0.5

q("Negative" | "Input: nothing Sentiment:") = 0.5
```

Buni ehtimolliklarni moslashtiruvchi (kalibrlovchi) chiziqli oâ€˜zgartirish yaratish orqali amalga oshiramiz
of $p$.

$\hat q = \text{Softmax}(W\hat p + b)$

Ushbu tenglama asl ehtimollar $\hat p$ ni oladi va og'irliklar $W$ hamda siljish $b$ ni qo'llaydi
ular. Ogâ€˜irliklar $W$ va siljish $b$ kalibrlash parametrlari boâ€˜lib, ular qoâ€˜llanilganda
kontekstsiz misolning ehtimollari $\hat p$ = [0.5, 0.5] ni beradi.

#### W va b ni hisoblash

Biz qandaydir tarzda og'irliklar $W$ va siljish $b$ ni hisoblashimiz kerak. Buni amalga oshirishning bir usuli quyidagicha:

$W = \text{diag}(\hat p)^{-1}$

$b = 0$

Garchi $W$ ning taâ€™rifi dastlab biroz gâ€™alati tuyulishi mumkin boâ€˜lsa-da, bu shunchaki $\hat p$ dagi har bir qiymatning teskarisini olish orqali asl ehtimolliklar $\hat p$ ni kalibrlangan ehtimolliklarga [0.5, 0.5] aylantiradigan $W$ ni topishdir.

Keling, bu yuqoridagi misolda ishlashini tekshirib koâ€˜raylik:

$\hat p = [0.9, 0.1]$

$W = \text{diag}(\hat p)^{-1} = \text{diag}([0.9, 0.1])^{-1}
= \begin{bmatrix}
   0.9 & 0 \\
   0 & 0.1
\end{bmatrix}^{-1}
= \begin{bmatrix}
   1.11 & 0 \\
   0 & 10
\end{bmatrix}$

$\hat q = \text{Softmax}(W\hat p + b) = \text{Softmax}(\begin{bmatrix}
   1.11 & 0 \\
   0 & 10
\end{bmatrix}*{[0.9, 0.1]} + 0)
= \text{Softmax}([1, 1])
=[0.5, 0.5]$

Yuqorida aytilganidek, biz ushbu jarayonni bir nechta turli context-free kirishlar uchun ham amalga oshiramiz va har bir context-free kirish uchun eng yaxshi ishlaydigan kalibrlash parametrlarini oâ€˜rtacha qilib, LLM uchun eng yaxshi kalibrlash parametrlarini topamiz. Bu shuni anglatadiki, yakuniy kalibrlash parametrlari ehtimol hech bir context-free kirishni aniq [0.5, 0.5] ga moslashtirmaydi.

### Yana bir usul

$b$ ham $-\hat p$ ga oâ€˜rnatilishi mumkin, va $W$ esa identitet matritsaga. Ushbu usul bajaradi
avlod vazifalarida tasniflash vazifalariga qaraganda yaxshiroq (@zhao2021calibrate).

## Xulosalar

LLMlar koâ€˜pincha maâ€™lum belgilar (yorliqlar)ga nisbatan ogâ€˜ish (xatolik)ga ega boâ€˜ladi. Kalibrlash ushbu ogâ€˜ishni bartaraf etish uchun qoâ€˜llanilishi mumkin.
