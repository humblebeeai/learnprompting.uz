---
sidebar_position: 1
title: "ðŸŸ¢ Kirish"
---


# Kirish

Ushbu bobda natijalarni yanada ishonchli qilish usullari, shuningdek, qanday qilib
Natijalar ishonchli boâ€˜lishini taâ€™minlash uchun tekshiruvlarni amalga oshiring.

Maâ€™lum darajada, koâ€˜pchilik
oldingi koâ€˜rib chiqilgan usullarning baâ€™zilari completionni yaxshilash bilan bogâ€˜liq
aniqlik va shuning uchun ishonchlilik, xususan oâ€˜z-oâ€˜ziga moslik (@wang2022selfconsistency).
Biroq, ishonchlilikni oshirish uchun foydalanish mumkin boâ€˜lgan boshqa bir qator usullar mavjud,
asosiy prompting strategiyalaridan tashqarida.

LLM have been found to be more reliable than we might expect
prompt notoâ€˜gâ€˜ri yozilgan, yomon ifodalangan boâ€˜lsa ham, uning nimani _anglatmoqchi_ ekanligini talqin qilishda
ifodalanadigan yoki hatto ataylab chalgâ€˜ituvchi promptlar (@webson2023itscomplicated).
bu qobiliyatga ega boâ€˜lsalar-da, ular hali ham turli muammolarni, jumladan, halusinatsiyalarni (@ye2022unreliability) namoyon qiladilar,
CoT prompting usullari bilan notoâ€˜gâ€˜ri tushuntirishlar (@ye2022unreliability),
va bir nechta ogâ€˜ishlar, jumladan, koâ€˜pchilik yorligâ€˜i ogâ€˜ishi, yaqinda boâ€˜lgan voqealarga ogâ€˜ish va keng tarqalgan token
bias (@zhao2021calibrate). Bundan tashqari, zero-shot CoT ayniqsa tarafkash boâ€˜lishi mumkin
nozik mavzular bilan ishlaganda (@shaikh2022second).

Ushbu muammolarning ba'zilariga keng tarqalgan yechimlar qatoriga _a priori_ ogâ€˜ishlarni yoâ€˜qotish uchun kalibratorlardan foydalanish kiradi,
va verifikatorlar orqali yakunlarni baholash, shuningdek, yakunlardagi xilma-xillikni oshirish.
